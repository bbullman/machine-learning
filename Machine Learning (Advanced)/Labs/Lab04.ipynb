{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmSkw4Cf25EN"
      },
      "source": [
        "# Lesson 5 - Assignment\n",
        "\n",
        "In this assignment, you will implement a Support Vector Machine Classifier  from scratch and compare the results to existing sklearn algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "RfB4IPp_25EQ"
      },
      "outputs": [],
      "source": [
        "# import packages\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from matplotlib.legend_handler import HandlerLine2D\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# make this notebook's output stable across runs\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyPdko2625ES"
      },
      "source": [
        "Question 1.1: Implement the cost function cost/objective function:\n",
        "<img src=\"https://miro.medium.com/max/688/1*JAS6rUTO7TDlrv4XZSMbsA.png\" alt=\"drawing\" width=\"600\"/>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "dccU1Dv325ES"
      },
      "outputs": [],
      "source": [
        "def compute_cost(W, X, Y, reg_strength=1000):\n",
        "    shape = X.shape[0]\n",
        "    distances = 1 - Y * (np.dot(X, W)) # array of distances\n",
        "    distances[distances < 0] = 0 # if it's negative, just set it to 0\n",
        "    loss = reg_strength * (np.sum(distances) / shape)\n",
        "    cost = 1 / 2 * np.dot(W, W) + loss # Do not need to do anything with b here as we insert it as part of the dataset (intercept)\n",
        "    return cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CV-myRNu25ET"
      },
      "source": [
        "Question 1.2: Write a method that calculate the cost gradient:\n",
        "<img src=\"https://miro.medium.com/max/866/1*ww3F21VMVGp2NKhm0VTesA.png\" alt=\"drawing\" width=\"600\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "Y_zqbsUt25ET"
      },
      "outputs": [],
      "source": [
        "def calculate_cost_gradient(W, X_batch, Y_batch, reg_strength=1000):\n",
        "    # type(Y_batch) == integer, so we need to convert it into an np array\n",
        "    Y_batch = np.array([Y_batch])\n",
        "    X_batch = np.array([X_batch])\n",
        "    distance = 1 - (Y_batch * np.dot(X_batch, W))\n",
        "    dw = np.zeros(len(W))\n",
        "    for index, d in enumerate(distance):\n",
        "        if max(0, d) == 0:\n",
        "          di = W\n",
        "        else:\n",
        "          di = W - (reg_strength * Y_batch[index] * X_batch[index])\n",
        "        dw += di\n",
        "    dw = dw/len(Y_batch)\n",
        "    return dw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGcvND0p25ET"
      },
      "source": [
        "Question 1.3: Write a method that performs stochastic Gradient descent as follows:\n",
        "- Caluclate the gradient of cost function i.e. ∇J(w)\n",
        "- Update the weights in the opposite direction to the gradient: w = w — ∝(∇J(w))\n",
        "- Repeat until conversion or until 5000 epochs are reached"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "lLGitoNJ25EU"
      },
      "outputs": [],
      "source": [
        "def sgd(data, outputs, learning_rate = 0.000001, max_epochs = 5000):\n",
        "    weights = np.zeros(data.shape[1])\n",
        "    nth = 0\n",
        "    prev_cost = float(\"inf\") # infinite cost! makes sense with gradient\n",
        "    cost_threshold = 0.01  # in percent\n",
        "    # stochastic gradient descent\n",
        "    for epoch in range(1, max_epochs):\n",
        "        # shuffle to prevent repeating update cycles\n",
        "        X, Y = shuffle(data, outputs)\n",
        "        for index, x in enumerate(X):\n",
        "            ascent = calculate_cost_gradient(weights, x, Y[index])\n",
        "            weights = weights - (learning_rate * ascent)\n",
        "            # convergence check on 2^nth epoch\n",
        "            if epoch == 2 ** nth or epoch == max_epochs - 1:\n",
        "                cost = compute_cost(weights, data, outputs)\n",
        "                print(\"Epoch is: {} and Cost is: {}\".format(epoch, cost))\n",
        "                # stoppage criterion, or when we want to stop descending\n",
        "                if abs(prev_cost-cost) < cost_threshold * prev_cost:\n",
        "                    return weights\n",
        "                prev_cost = cost\n",
        "                nth += 1\n",
        "    return weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIjt0-hg25EU"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqZbIlz725EU",
        "outputId": "2712f021-80d5-4117-da60-e7e5bda45b99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    3.6216  8.6661  -2.8073  -0.44699  0\n",
            "0  4.54590  8.1674  -2.4586  -1.46210  0\n",
            "1  3.86600 -2.6383   1.9242   0.10645  0\n",
            "2  3.45660  9.5228  -4.0112  -3.59440  0\n",
            "3  0.32924 -4.4552   4.5718  -0.98880  0\n",
            "4  4.36840  9.6718  -3.9606  -3.16250  0\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('data_banknote_authentication.csv')\n",
        "\n",
        "print(data.head())\n",
        "\n",
        "Y = data.iloc[:, -1]\n",
        "X = data.iloc[:, 1:4]\n",
        "X.insert(loc=len(X.columns), column='intercept', value=1) #inserts the B column\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl3tUW6225EV"
      },
      "source": [
        "Question 4: Train and evaluate an SVC using the banknote_authentication data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFX5NcrO25EV",
        "outputId": "32b319f5-54db-43dc-f04f-b6fd4864f342"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training started...\n",
            "Epoch is: 1 and Cost is: 1000.0\n",
            "Epoch is: 2 and Cost is: 722.963263375125\n",
            "Epoch is: 4 and Cost is: 627.73561795842\n",
            "Epoch is: 8 and Cost is: 564.3342958674476\n",
            "Epoch is: 16 and Cost is: 557.8744461848763\n",
            "Epoch is: 32 and Cost is: 557.8453955476957\n",
            "training finished.\n",
            "weights are: [-0.00950043  0.02362466 -0.10625211  1.15041795]\n",
            "accuracy on test dataset with initial weights (W) using SGD: 0.44808743169398907\n",
            "sklearn linear kernel training used for weights started...\n",
            "sklearn linear kernel training finished....\n",
            "weights are: [[-5.09637313e-01 -3.49295369e-01 -5.31564418e-01 -2.39808173e-14]]\n",
            "accuracy on test dataset with initial weights (W2) using sklearn linear kernel: 0.30965391621129323\n"
          ]
        }
      ],
      "source": [
        "# train the model\n",
        "print(\"training started...\")\n",
        "W = sgd(X_train.to_numpy(), y_train.to_numpy()) # this results in an extremely low accuracy\n",
        "print(\"training finished.\")\n",
        "print(\"weights are: {}\".format(W))\n",
        "\n",
        "y_test_predicted = np.array([])\n",
        "for i in range(X_test.shape[0]):\n",
        "    yp = np.sign(np.dot(W, X_test.to_numpy()[i]))\n",
        "    y_test_predicted = np.append(y_test_predicted, yp)\n",
        "print(\"accuracy on test dataset with initial weights (W) using SGD: {}\".format(accuracy_score(y_test.to_numpy(), y_test_predicted)))\n",
        "\n",
        "\n",
        "# testing a sklearn model for comparison quickly\n",
        "print(\"sklearn linear kernel training used for weights started...\")\n",
        "from sklearn.svm import SVC\n",
        "svc_linear_clf = SVC(kernel='linear', random_state=42)\n",
        "svc_linear_clf.fit(X_train, y_train)\n",
        "W2 = svc_linear_clf.coef_\n",
        "print(\"sklearn linear kernel training finished....\")\n",
        "print(\"weights are: {}\".format(W2))\n",
        "\n",
        "y_test_predicted_w2 = np.array([])\n",
        "for i in range(X_test.shape[0]):\n",
        "    yp2 = np.sign(np.dot(W2, X_test.to_numpy()[i]))\n",
        "    y_test_predicted_w2 = np.append(y_test_predicted_w2, yp2)\n",
        "print(\"accuracy on test dataset with initial weights (W2) using sklearn linear kernel: {}\".format(accuracy_score(y_test.to_numpy(), y_test_predicted_w2)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHaaItPH25EV"
      },
      "source": [
        "[Bonus] Question 5: Train and evaluate an SKLEARN SVC model, and compare the results to your model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Note\n",
        "\n",
        "Since I did the linear above (which had extremely low values), I'll do 'rbf' kernel here."
      ],
      "metadata": {
        "id": "G2TthEvwZyyZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "zpItPpjS25EV"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "svc_clf = SVC(kernel='rbf', random_state=42, C=10) # C=float(\"inf\") # linear gives lower accuracy\n",
        "svc_clf.fit(X_train, y_train)\n",
        "y_pred_svc_clf = svc_clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred_svc_clf))\n",
        "accuracy_score(y_test, y_pred_svc_clf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1p85h9lz6lEC",
        "outputId": "3552b5c9-eeae-4e28-f17a-53305f7717f0"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[289  14]\n",
            " [ 32 214]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9162112932604736"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR09Rs1W25EV"
      },
      "source": [
        "Question 6: Create a new text cell in your Notebook: Complete a 50-100 word summary (or short description of your thinking in applying this week's learning to the solution) of your experience in this assignment. Include: What was your incoming experience with this model, if any? what steps you took, what obstacles you encountered. how you link this exercise to real-world, machine learning problem-solving. (What steps were missing? What else do you need to learn?) This summary allows your instructor to know how you are doing and allot points for your effort in thinking and planning, and making connections to real-world work."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q.6\n",
        "\n",
        "1. I have experience with these models mostly in an anecdotal way, testing various apps and tools for image recognition (ie: hot dog, not hot dog tests).\n",
        "2. I am admittedly not great at the math portion so there's a lot of referring to notes and resouces, remembering variables meanings, etc.\n",
        "3. I would absolutely apply this model to any sort of binary classification heavily used in visual or audio recognition models.\n",
        "4. Some steps I would've found helpful would've been a visualization of the output. I think the visuals are really nice with SVC models. I tried to create one myself but got hung up on it so I removed it."
      ],
      "metadata": {
        "id": "nUpbXA2Xe3Qt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "r5hh3HQY25EV"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "\n",
        "jupyter nbconvert --to html /content/Lab04.ipynb"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}