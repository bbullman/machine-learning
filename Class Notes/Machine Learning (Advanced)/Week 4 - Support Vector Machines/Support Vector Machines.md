## Maximizing Geometric Margin

The geometric margin is used to compute the support vectors for a hyperplane.

Maximum margin classifier leads to a quadratic optimization problem.

## Non-Linear SVM

Datasets that are linearly separable work out well.

If the dataset is too difficult to separate: you can do a curved line through the data.

Non-linearly separation of data sets is accomplished using a kernel function, of which there are several.

## Kernel Tricks

* Useful in higher dimension spaces. Predictive ability may drop off.
* Features are non-parametric. Computational cost is higher.
* Kernel functions can be added together as ensembles to create even more complex hyperplanes. Computational cost is higher.
* Give a highly optimal hyperplane. No probability function.